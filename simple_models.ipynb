{"cells":[{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"DDJwQPZcupab","new_sheet":false,"run_control":{"read_only":false}},"source":["# CS 6476 Assignment 2 | Part 0: Simple Models for Image Classification"]},{"cell_type":"markdown","metadata":{"id":"ez5i-ShSA9G4"},"source":["# AIM\n"," The aim of this assignment is to assess simple models like linear classifier and KNN classifier on CIFAR-10 image classification dataset."]},{"cell_type":"markdown","metadata":{"id":"p9qbfhhvA9G4"},"source":["# Summary\n","The goal of this part of the assignment is to evaluate how simple models we implemented in the last assignment like linear classifier and KNN classifier work on image classification problem on a simple CIFAR-10 dataset.\n","## Learning Objectives\n","Compare and contrast simple classifiers aginst more complex models we will learn through the course of this assignment and answer conceptual questions based on that.\n","## Grading Schema\n","This part of the assignment will be not be graded from a coding perspective. There maybe some conceptual questions asked to answer in the report.\n","## Time Commitement\n","This part of the assignment should take about 1 hr of effort to go through.\n","## Computational Requirements\n","This part of the assignment should not take more than 20 mins in total to execute each part."]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"Q7ymI0aZ2W1b","new_sheet":false,"run_control":{"read_only":false}},"source":["# Setup\n","If running on local system install the packages through following commands.\n","```\n","pip install opencv-python\n","pip install torchvision\n","pip install torch\n","pip install scikit-learn\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"qCZabdDwA9G4"},"source":["## Colab Setup\n","First, run the following cell to load the \"autoreload\" extension. The \"autoreload\" extension allows you to automatically reload (re-import) Python modules that you've imported or defined when they change. This is particularly useful when you are actively developing or modifying code in external modules and want those changes to be automatically reflected in your notebook without manually restarting the kernel. Those not running colab avoid running the cells associated to `colab setup`"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"IfvlU3PLA9G5","executionInfo":{"status":"ok","timestamp":1694127272431,"user_tz":240,"elapsed":92,"user":{"displayName":"Derrick Joyce","userId":"06313486336305651602"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6bc83e9a-3292-451e-ba06-b520cc2775b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]}],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","metadata":{"id":"TG3SJ7u7A9G5"},"source":["Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!) and copy the authorization code into the text box that appears below."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RQ7L-yQ-A9G5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694122664581,"user_tz":240,"elapsed":14649,"user":{"displayName":"Derrick Joyce","userId":"06313486336305651602"}},"outputId":"14d2d93f-9275-4c2d-94a1-a7e1e58947c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"LAt9dWLIA9G5"},"source":["Now recall the path in your Google Drive where you uploaded this notebook, fill it in below. If everything is working correctly then running the folowing cell should print the filenames from the assignment:"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"LFn7UAu1A9G5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694127275213,"user_tz":240,"elapsed":117,"user":{"displayName":"Derrick Joyce","userId":"06313486336305651602"}},"outputId":"8dd66ba1-e0a7-4c08-8382-35e3ef0e320a"},"outputs":[{"output_type":"stream","name":"stdout","text":["['simple_models.ipynb', 'simple_models.py', 'convolutional_networks.py', 'fully_connected_networks.ipynb', 'a2_helper.py', 'convolutional_networks.ipynb', 'fully_connected_networks.py', 'transfer_learning.ipynb', 'cs6476', '__pycache__']\n"]}],"source":["import os\n","\n","# TODO: Fill in the Google Drive path where you uploaded the assignment\n","# Example: If you create a CV2023 folder and put all the files under A2 folder, then 'CV2023/A2'\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'CS 6476 Intro to Computer Vision/Assignment 2' #enter file name as the above example\n","GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","print(os.listdir(GOOGLE_DRIVE_PATH))"]},{"cell_type":"markdown","metadata":{"id":"9Skgd-OKA9G5"},"source":["Once you have successfully mounted your Google Drive and located the path to this assignment, run the following cell to allow us to import from the .py files of this part of the assignment. If it works correctly, it should print the message:\n","```\n","Hello from simple_models.py!\n","Hello from a2_helper.py!\n","```"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"5p3ZccFjA9G5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694127282963,"user_tz":240,"elapsed":4611,"user":{"displayName":"Derrick Joyce","userId":"06313486336305651602"}},"outputId":"a01281f7-b24b-43b3-ba60-688417e560ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Hello from simple_models.py!\n","Hello from a2_helper.py!\n","simple_models.py last edited on Thu Sep  7 16:00:28 2023\n"]}],"source":["import sys\n","sys.path.append(GOOGLE_DRIVE_PATH)\n","\n","import time, os\n","os.environ[\"TZ\"] = \"US/Eastern\"\n","time.tzset()\n","\n","from simple_models import hello_simple_models\n","hello_simple_models()\n","\n","from a2_helper import hello_helper\n","hello_helper()\n","\n","simple_models_path = os.path.join(GOOGLE_DRIVE_PATH, 'simple_models.py')\n","simple_models_edit_time = time.ctime(os.path.getmtime(simple_models_path))\n","print('simple_models.py last edited on %s' % simple_models_edit_time)"]},{"cell_type":"markdown","metadata":{"id":"ZCQy6vB-A9G6"},"source":["On colab install dependecies using:\n","```\n","!pip install opencv-python\n","!pip install torchvision\n","!pip install torch\n","!pip install scikit-learn\n","```"]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"fN1SShPR4lJV","new_sheet":false,"run_control":{"read_only":false}},"source":["# Imports\n","Import requisit packages to work with the provided files for part-1 of the assignment."]},{"cell_type":"code","execution_count":9,"metadata":{"button":false,"deletable":true,"id":"VUCKw4Tl1ddj","new_sheet":false,"run_control":{"read_only":false},"executionInfo":{"status":"ok","timestamp":1694127285146,"user_tz":240,"elapsed":83,"user":{"displayName":"Derrick Joyce","userId":"06313486336305651602"}}},"outputs":[],"source":["import cs6476\n","import torch\n","import torchvision\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from cs6476 import Solver\n","\n","plt.rcParams['figure.figsize'] = (10.0, 8.0)\n","plt.rcParams['font.size'] = 16"]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"ynKS05gJ4iBo","new_sheet":false,"run_control":{"read_only":false}},"source":["# Data preprocessing"]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"-Yv3zQYw5B3s","new_sheet":false,"run_control":{"read_only":false}},"source":["## Load and Visualize the CIFAR-10 dataset\n","We will first load the CIFAR-10 dataset. The utility function `cs6476.data.preprocess_cifar10()` returns the entire CIFAR-10 dataset as a set of six **Torch tensors** while also preprocessing the RGB images. We then split the data into 3 components, Train, Validate and Test.\n","\n","- `X_train` contains all training images (real numbers in the range $[0, 1]$)\n","- `y_train` contains all training labels (integers in the range $[0, 9]$)\n","- `X_val` contains all validation images\n","- `y_val` contains all validation labels\n","- Note: The seed value should remain untouched while coding your experiments, to ensure consistency in results on gradescope.\n","\n","- To know more about CIFAR datasets read https://www.cs.toronto.edu/~kriz/cifar.html\n","- Please note that you have to use your `gtid` to set seed for all experiments and code. It will be crucial for accurate testing over gradescope"]},{"cell_type":"code","execution_count":10,"metadata":{"button":false,"deletable":true,"id":"V2mFlFmQ1ddm","new_sheet":false,"run_control":{"read_only":false},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694127289562,"user_tz":240,"elapsed":2167,"user":{"displayName":"Derrick Joyce","userId":"06313486336305651602"}},"outputId":"b76f6676-7696-46ab-96e0-17cb8faf201f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train data shape:  torch.Size([40000, 3072])\n","Train labels shape:  torch.Size([40000])\n","Validation data shape:  torch.Size([10000, 3072])\n","Validation labels shape:  torch.Size([10000])\n"]}],"source":["cs6476.utils.reset_seed(6476)\n","data_dict = cs6476.data.preprocess_cifar10(cuda=False, dtype=torch.float64)\n","print('Train data shape: ', data_dict['X_train'].shape)\n","print('Train labels shape: ', data_dict['y_train'].shape)\n","print('Validation data shape: ', data_dict['X_val'].shape)\n","print('Validation labels shape: ', data_dict['y_val'].shape)"]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"ZeH0OvuEe1CN","new_sheet":false,"run_control":{"read_only":false},"tags":["pdf-title"]},"source":["# Linear Classifier"]},{"cell_type":"markdown","metadata":{"button":false,"deletable":true,"id":"3Qiu9_4pe1CP","new_sheet":false,"run_control":{"read_only":false},"tags":["pdf-ignore"]},"source":["We have implemeted a simple linear classifier for you. Play around with parameters like epochs and learning rate. The results from this experimentation will be used in QA part of the assignment.\n","  "]},{"cell_type":"code","execution_count":11,"metadata":{"id":"w64cb1UtA9G7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694127550842,"user_tz":240,"elapsed":261285,"user":{"displayName":"Derrick Joyce","userId":"06313486336305651602"}},"outputId":"3bb9aab9-f8d8-4ab9-e4f6-1eb2982bfc53"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [10/1000], Loss: 2.1224\n","Training Accuracy: 0.3522\n","Validation Accuracy: 0.3379\n","Epoch [20/1000], Loss: 2.0826\n","Training Accuracy: 0.3699\n","Validation Accuracy: 0.3506\n","Epoch [30/1000], Loss: 2.0675\n","Training Accuracy: 0.3872\n","Validation Accuracy: 0.3633\n","Epoch [40/1000], Loss: 2.0597\n","Training Accuracy: 0.3965\n","Validation Accuracy: 0.3686\n","Epoch [50/1000], Loss: 2.0527\n","Training Accuracy: 0.4033\n","Validation Accuracy: 0.3742\n","Epoch [60/1000], Loss: 2.0476\n","Training Accuracy: 0.4087\n","Validation Accuracy: 0.3769\n","Epoch [70/1000], Loss: 2.0428\n","Training Accuracy: 0.4144\n","Validation Accuracy: 0.3819\n","Epoch [80/1000], Loss: 2.0395\n","Training Accuracy: 0.4173\n","Validation Accuracy: 0.3850\n","Epoch [90/1000], Loss: 2.0344\n","Training Accuracy: 0.4270\n","Validation Accuracy: 0.3911\n","Epoch [100/1000], Loss: 2.0347\n","Training Accuracy: 0.4219\n","Validation Accuracy: 0.3861\n","Epoch [110/1000], Loss: 2.0293\n","Training Accuracy: 0.4325\n","Validation Accuracy: 0.3957\n","Epoch [120/1000], Loss: 2.0292\n","Training Accuracy: 0.4294\n","Validation Accuracy: 0.3910\n","Epoch [130/1000], Loss: 2.0262\n","Training Accuracy: 0.4349\n","Validation Accuracy: 0.3946\n","Epoch [140/1000], Loss: 2.0243\n","Training Accuracy: 0.4373\n","Validation Accuracy: 0.3945\n","Epoch [150/1000], Loss: 2.0225\n","Training Accuracy: 0.4395\n","Validation Accuracy: 0.3955\n","Epoch [160/1000], Loss: 2.0208\n","Training Accuracy: 0.4428\n","Validation Accuracy: 0.3974\n","Epoch [170/1000], Loss: 2.0192\n","Training Accuracy: 0.4442\n","Validation Accuracy: 0.3985\n","Epoch [180/1000], Loss: 2.0177\n","Training Accuracy: 0.4459\n","Validation Accuracy: 0.3993\n","Epoch [190/1000], Loss: 2.0163\n","Training Accuracy: 0.4476\n","Validation Accuracy: 0.3995\n","Epoch [200/1000], Loss: 2.0150\n","Training Accuracy: 0.4491\n","Validation Accuracy: 0.4003\n","Epoch [210/1000], Loss: 2.0138\n","Training Accuracy: 0.4510\n","Validation Accuracy: 0.4008\n","Epoch [220/1000], Loss: 2.0126\n","Training Accuracy: 0.4525\n","Validation Accuracy: 0.4007\n","Epoch [230/1000], Loss: 2.0115\n","Training Accuracy: 0.4536\n","Validation Accuracy: 0.4012\n","Epoch [240/1000], Loss: 2.0104\n","Training Accuracy: 0.4545\n","Validation Accuracy: 0.4018\n","Epoch [250/1000], Loss: 2.0093\n","Training Accuracy: 0.4558\n","Validation Accuracy: 0.4020\n","Epoch [260/1000], Loss: 2.0083\n","Training Accuracy: 0.4572\n","Validation Accuracy: 0.4023\n","Epoch [270/1000], Loss: 2.0074\n","Training Accuracy: 0.4585\n","Validation Accuracy: 0.4022\n","Epoch [280/1000], Loss: 2.0064\n","Training Accuracy: 0.4601\n","Validation Accuracy: 0.4020\n","Epoch [290/1000], Loss: 2.0055\n","Training Accuracy: 0.4610\n","Validation Accuracy: 0.4016\n","Epoch [300/1000], Loss: 2.0046\n","Training Accuracy: 0.4620\n","Validation Accuracy: 0.4018\n","Epoch [310/1000], Loss: 2.0037\n","Training Accuracy: 0.4634\n","Validation Accuracy: 0.4021\n","Epoch [320/1000], Loss: 2.0029\n","Training Accuracy: 0.4645\n","Validation Accuracy: 0.4030\n","Epoch [330/1000], Loss: 2.0021\n","Training Accuracy: 0.4657\n","Validation Accuracy: 0.4033\n","Epoch [340/1000], Loss: 2.0012\n","Training Accuracy: 0.4669\n","Validation Accuracy: 0.4039\n","Epoch [350/1000], Loss: 2.0003\n","Training Accuracy: 0.4677\n","Validation Accuracy: 0.4030\n","Epoch [360/1000], Loss: 2.0004\n","Training Accuracy: 0.4677\n","Validation Accuracy: 0.4024\n","Epoch [370/1000], Loss: 1.9996\n","Training Accuracy: 0.4687\n","Validation Accuracy: 0.4027\n","Epoch [380/1000], Loss: 1.9986\n","Training Accuracy: 0.4699\n","Validation Accuracy: 0.4027\n","Epoch [390/1000], Loss: 1.9979\n","Training Accuracy: 0.4710\n","Validation Accuracy: 0.4032\n","Epoch [400/1000], Loss: 1.9972\n","Training Accuracy: 0.4716\n","Validation Accuracy: 0.4045\n","Epoch [410/1000], Loss: 1.9965\n","Training Accuracy: 0.4726\n","Validation Accuracy: 0.4040\n","Epoch [420/1000], Loss: 1.9957\n","Training Accuracy: 0.4734\n","Validation Accuracy: 0.4048\n","Epoch [430/1000], Loss: 1.9951\n","Training Accuracy: 0.4742\n","Validation Accuracy: 0.4040\n","Epoch [440/1000], Loss: 1.9946\n","Training Accuracy: 0.4745\n","Validation Accuracy: 0.4039\n","Epoch [450/1000], Loss: 1.9951\n","Training Accuracy: 0.4737\n","Validation Accuracy: 0.4042\n","Epoch [460/1000], Loss: 1.9948\n","Training Accuracy: 0.4736\n","Validation Accuracy: 0.4027\n","Epoch [470/1000], Loss: 1.9934\n","Training Accuracy: 0.4756\n","Validation Accuracy: 0.4044\n","Epoch [480/1000], Loss: 1.9929\n","Training Accuracy: 0.4762\n","Validation Accuracy: 0.4034\n","Epoch [490/1000], Loss: 1.9923\n","Training Accuracy: 0.4771\n","Validation Accuracy: 0.4041\n","Epoch [500/1000], Loss: 1.9917\n","Training Accuracy: 0.4777\n","Validation Accuracy: 0.4036\n","Epoch [510/1000], Loss: 1.9909\n","Training Accuracy: 0.4789\n","Validation Accuracy: 0.4045\n","Epoch [520/1000], Loss: 1.9901\n","Training Accuracy: 0.4803\n","Validation Accuracy: 0.4055\n","Epoch [530/1000], Loss: 1.9895\n","Training Accuracy: 0.4805\n","Validation Accuracy: 0.4060\n","Epoch [540/1000], Loss: 1.9893\n","Training Accuracy: 0.4814\n","Validation Accuracy: 0.4058\n","Epoch [550/1000], Loss: 1.9886\n","Training Accuracy: 0.4820\n","Validation Accuracy: 0.4061\n","Epoch [560/1000], Loss: 1.9879\n","Training Accuracy: 0.4830\n","Validation Accuracy: 0.4067\n","Epoch [570/1000], Loss: 1.9873\n","Training Accuracy: 0.4835\n","Validation Accuracy: 0.4073\n","Epoch [580/1000], Loss: 1.9875\n","Training Accuracy: 0.4823\n","Validation Accuracy: 0.4059\n","Epoch [590/1000], Loss: 1.9870\n","Training Accuracy: 0.4830\n","Validation Accuracy: 0.4065\n","Epoch [600/1000], Loss: 1.9877\n","Training Accuracy: 0.4817\n","Validation Accuracy: 0.4060\n","Epoch [610/1000], Loss: 1.9870\n","Training Accuracy: 0.4829\n","Validation Accuracy: 0.4064\n","Epoch [620/1000], Loss: 1.9868\n","Training Accuracy: 0.4827\n","Validation Accuracy: 0.4063\n","Epoch [630/1000], Loss: 1.9849\n","Training Accuracy: 0.4855\n","Validation Accuracy: 0.4074\n","Epoch [640/1000], Loss: 1.9843\n","Training Accuracy: 0.4861\n","Validation Accuracy: 0.4080\n","Epoch [650/1000], Loss: 1.9847\n","Training Accuracy: 0.4851\n","Validation Accuracy: 0.4084\n","Epoch [660/1000], Loss: 1.9858\n","Training Accuracy: 0.4836\n","Validation Accuracy: 0.4081\n","Epoch [670/1000], Loss: 1.9851\n","Training Accuracy: 0.4849\n","Validation Accuracy: 0.4085\n","Epoch [680/1000], Loss: 1.9849\n","Training Accuracy: 0.4858\n","Validation Accuracy: 0.4082\n","Epoch [690/1000], Loss: 1.9843\n","Training Accuracy: 0.4867\n","Validation Accuracy: 0.4084\n","Epoch [700/1000], Loss: 1.9837\n","Training Accuracy: 0.4870\n","Validation Accuracy: 0.4079\n","Epoch [710/1000], Loss: 1.9829\n","Training Accuracy: 0.4881\n","Validation Accuracy: 0.4081\n","Epoch [720/1000], Loss: 1.9820\n","Training Accuracy: 0.4892\n","Validation Accuracy: 0.4081\n","Validation Accuracy: 0.4086\n","Epoch [740/1000], Loss: 1.9812\n","Training Accuracy: 0.4900\n","Validation Accuracy: 0.4087\n","Epoch [750/1000], Loss: 1.9810\n","Training Accuracy: 0.4902\n","Validation Accuracy: 0.4089\n","Epoch [760/1000], Loss: 1.9816\n","Training Accuracy: 0.4891\n","Validation Accuracy: 0.4084\n","Epoch [770/1000], Loss: 1.9798\n","Training Accuracy: 0.4917\n","Validation Accuracy: 0.4094\n","Epoch [780/1000], Loss: 1.9790\n","Training Accuracy: 0.4929\n","Validation Accuracy: 0.4092\n","Epoch [790/1000], Loss: 1.9793\n","Training Accuracy: 0.4924\n","Validation Accuracy: 0.4096\n","Epoch [800/1000], Loss: 1.9800\n","Training Accuracy: 0.4909\n","Validation Accuracy: 0.4087\n","Epoch [810/1000], Loss: 1.9780\n","Training Accuracy: 0.4946\n","Validation Accuracy: 0.4099\n","Epoch [820/1000], Loss: 1.9775\n","Training Accuracy: 0.4947\n","Validation Accuracy: 0.4104\n","Epoch [830/1000], Loss: 1.9775\n","Training Accuracy: 0.4942\n","Validation Accuracy: 0.4097\n","Epoch [840/1000], Loss: 1.9787\n","Training Accuracy: 0.4923\n","Validation Accuracy: 0.4095\n","Epoch [850/1000], Loss: 1.9764\n","Training Accuracy: 0.4965\n","Validation Accuracy: 0.4103\n","Epoch [860/1000], Loss: 1.9755\n","Training Accuracy: 0.4969\n","Validation Accuracy: 0.4093\n","Epoch [870/1000], Loss: 1.9753\n","Training Accuracy: 0.4966\n","Validation Accuracy: 0.4089\n","Epoch [880/1000], Loss: 1.9775\n","Training Accuracy: 0.4931\n","Validation Accuracy: 0.4085\n","Epoch [890/1000], Loss: 1.9773\n","Training Accuracy: 0.4937\n","Validation Accuracy: 0.4104\n","Epoch [900/1000], Loss: 1.9773\n","Training Accuracy: 0.4942\n","Validation Accuracy: 0.4097\n","Epoch [910/1000], Loss: 1.9766\n","Training Accuracy: 0.4961\n","Validation Accuracy: 0.4100\n","Epoch [920/1000], Loss: 1.9752\n","Training Accuracy: 0.4980\n","Validation Accuracy: 0.4098\n","Epoch [930/1000], Loss: 1.9745\n","Training Accuracy: 0.4989\n","Validation Accuracy: 0.4105\n","Epoch [940/1000], Loss: 1.9744\n","Training Accuracy: 0.4985\n","Validation Accuracy: 0.4096\n","Epoch [950/1000], Loss: 1.9752\n","Training Accuracy: 0.4961\n","Validation Accuracy: 0.4094\n","Epoch [960/1000], Loss: 1.9737\n","Training Accuracy: 0.4980\n","Validation Accuracy: 0.4098\n","Epoch [970/1000], Loss: 1.9731\n","Training Accuracy: 0.4994\n","Validation Accuracy: 0.4098\n","Epoch [980/1000], Loss: 1.9729\n","Training Accuracy: 0.4999\n","Validation Accuracy: 0.4101\n","Epoch [990/1000], Loss: 1.9721\n","Training Accuracy: 0.5005\n","Validation Accuracy: 0.4096\n","Epoch [1000/1000], Loss: 1.9730\n","Training Accuracy: 0.4988\n","Validation Accuracy: 0.4099\n"]}],"source":["from simple_models import linear_classifier\n","\n","linear_classifier(data_dict, num_epochs=1000, lr=0.99)"]},{"cell_type":"markdown","metadata":{"id":"gytA5o1CA9G8"},"source":["# KNN CLassifier"]},{"cell_type":"markdown","metadata":{"id":"GXQI6RJcA9G8"},"source":["We have implemeted a simple KNN classifier for you. Test it on the CIFAR-10 Dataset, play with parameters like neighbors. The results from this experimentation will be used in QA part of the assignment."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XpqMeSj4A9G8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a7505ba8-15a7-4aa9-8a7e-60d3a15996b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 0.3247\n","Validation Accuracy: 0.3237\n","Validation Accuracy: 0.3230\n","Validation Accuracy: 0.3223\n"]}],"source":["from simple_models import knn\n","\n","knn(data_dict, neighbors=6)\n","knn(data_dict, neighbors=7)\n","knn(data_dict, neighbors=8)\n","knn(data_dict, neighbors=9)\n","knn(data_dict, neighbors=10)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"dG3y0XUeBDL1"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}